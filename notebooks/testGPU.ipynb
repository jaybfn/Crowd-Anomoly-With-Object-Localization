{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Asus\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:01<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:01<?, ? url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/ url]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/ url]\n",
      "\u001b[A\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/ url]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/ url]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/ url]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/ url]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:02,  1.03s/ url]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:02,  1.03s/ url]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:02,  1.03s/ url]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:02,  1.03s/ url]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:02,  1.03s/ url]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:02,  1.03s/ url]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:02,  1.03s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.31 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.31 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.31 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.31 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.31 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.31 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.51 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.51 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  2.51 url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:02<00:00,  1.86 file/s]\n",
      "Dl Size...: 100%|██████████| 10/10 [00:02<00:00,  4.64 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  1.85 url/s]\n",
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\Asus\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "\n",
    "mnist_train, mnist_test = datasets['train'], datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also do info.splits.total_num_examples to get the total\n",
    "# number of examples in the dataset.\n",
    "\n",
    "num_train_examples = info.splits['train'].num_examples\n",
    "num_test_examples = info.splits['test'].num_examples\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint directory to store the checkpoints.\n",
    "checkpoint_dir = '../training_checkpoints'\n",
    "# Define the name of the checkpoint files.\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for decaying the learning rate.\n",
    "# You can define any decay function you need.\n",
    "def decay(epoch):\n",
    "  if epoch < 3:\n",
    "    return 1e-3\n",
    "  elif epoch >= 3 and epoch < 7:\n",
    "    return 1e-4\n",
    "  else:\n",
    "    return 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a callback for printing the learning rate at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print('\\nLearning rate for epoch {} is {}'.format(        epoch + 1, model.optimizer.lr.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the callbacks together.\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                       save_weights_only=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
    "    PrintLR()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "938/938 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.8418\n",
      "Learning rate for epoch 1 is 0.0010000000474974513\n",
      "938/938 [==============================] - 6s 4ms/step - loss: 0.4524 - accuracy: 0.8418 - lr: 0.0010\n",
      "Epoch 2/12\n",
      "931/938 [============================>.] - ETA: 0s - loss: 0.3040 - accuracy: 0.8918\n",
      "Learning rate for epoch 2 is 0.0010000000474974513\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3038 - accuracy: 0.8919 - lr: 0.0010\n",
      "Epoch 3/12\n",
      "933/938 [============================>.] - ETA: 0s - loss: 0.2628 - accuracy: 0.9059\n",
      "Learning rate for epoch 3 is 0.0010000000474974513\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2628 - accuracy: 0.9058 - lr: 0.0010\n",
      "Epoch 4/12\n",
      "930/938 [============================>.] - ETA: 0s - loss: 0.2149 - accuracy: 0.9230\n",
      "Learning rate for epoch 4 is 9.999999747378752e-05\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2152 - accuracy: 0.9230 - lr: 1.0000e-04\n",
      "Epoch 5/12\n",
      "931/938 [============================>.] - ETA: 0s - loss: 0.2086 - accuracy: 0.9259\n",
      "Learning rate for epoch 5 is 9.999999747378752e-05\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.2082 - accuracy: 0.9260 - lr: 1.0000e-04\n",
      "Epoch 6/12\n",
      "936/938 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.9275\n",
      "Learning rate for epoch 6 is 9.999999747378752e-05\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 0.2035 - accuracy: 0.9275 - lr: 1.0000e-04\n",
      "Epoch 7/12\n",
      "933/938 [============================>.] - ETA: 0s - loss: 0.1993 - accuracy: 0.9290\n",
      "Learning rate for epoch 7 is 9.999999747378752e-05\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1995 - accuracy: 0.9288 - lr: 1.0000e-04\n",
      "Epoch 8/12\n",
      "935/938 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9321\n",
      "Learning rate for epoch 8 is 9.999999747378752e-06\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1931 - accuracy: 0.9320 - lr: 1.0000e-05\n",
      "Epoch 9/12\n",
      "934/938 [============================>.] - ETA: 0s - loss: 0.1921 - accuracy: 0.9321\n",
      "Learning rate for epoch 9 is 9.999999747378752e-06\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1924 - accuracy: 0.9320 - lr: 1.0000e-05\n",
      "Epoch 10/12\n",
      "926/938 [============================>.] - ETA: 0s - loss: 0.1920 - accuracy: 0.9325\n",
      "Learning rate for epoch 10 is 9.999999747378752e-06\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1920 - accuracy: 0.9324 - lr: 1.0000e-05\n",
      "Epoch 11/12\n",
      "929/938 [============================>.] - ETA: 0s - loss: 0.1918 - accuracy: 0.9326\n",
      "Learning rate for epoch 11 is 9.999999747378752e-06\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1915 - accuracy: 0.9327 - lr: 1.0000e-05\n",
      "Epoch 12/12\n",
      "930/938 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9326\n",
      "Learning rate for epoch 12 is 9.999999747378752e-06\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.1911 - accuracy: 0.9326 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a056b27fa0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 12\n",
    "\n",
    "model.fit(train_dataset, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6688047dcce87501\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6688047dcce87501\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deepL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b90cab7ea642421f44636989edaf96d86cb1abe354b45ce6eed3b362842c2584"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
